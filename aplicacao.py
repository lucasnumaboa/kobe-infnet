"""
Pipeline de aplica√ß√£o para o projeto de previs√£o de arremessos do Kobe Bryant.
Este m√≥dulo carrega o modelo treinado, aplica-o aos dados de produ√ß√£o e registra m√©tricas.
"""

import os
import pandas as pd
import mlflow
# Removendo import mlflow.pycaret que n√£o existe
from pathlib import Path
from datetime import datetime
import logging
from sklearn.metrics import log_loss, f1_score
import joblib
import yaml
import matplotlib.pyplot as plt
import seaborn as sns

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def get_project_root():
    """Get the absolute path to the project root directory."""
    # Start from the current file and go up until we find the project root
    current_path = Path(__file__).resolve()
    project_root = current_path.parent
    return project_root

def log_step(message):
    """Log a step to the log file."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open("log.txt", "a") as f:
        f.write(f"[{timestamp}] PIPELINE APLICACAO: {message}\n")
    logger.info(message)

def load_production_data():
    """Load the production dataset."""
    log_step("Carregando dados de produ√ß√£o")
    project_root = get_project_root()
    prod_data_path = os.path.join(project_root, "data", "raw", "dataset_kobe_prod.parquet")
    log_step(f"Lendo dados de: {prod_data_path}")
    
    return pd.read_parquet(prod_data_path)

def filter_production_data(df):
    """
    Filter the production data to include only the required columns and remove rows with missing values.
    """
    log_step("Filtrando dados para incluir apenas as colunas especificadas")
    
    # Verificar colunas dispon√≠veis no dataset
    log_step(f"Columns available in dataset: {df.columns.tolist()}")
    
    # Colunas espec√≠ficas conforme o enunciado
    columns_to_keep = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance']
    
    # Verificar se existe shot_made_flag nos dados de produ√ß√£o
    if 'shot_made_flag' in df.columns:
        columns_to_keep.append('shot_made_flag')
        log_step("Coluna shot_made_flag encontrada nos dados de produ√ß√£o")
        has_target = True
    else:
        log_step("Coluna shot_made_flag n√£o encontrada nos dados de produ√ß√£o")
        has_target = False
    
    # Filtrar colunas
    df_filtered = df[columns_to_keep]
    
    # Registrar formato inicial
    log_step(f"Formato inicial dos dados filtrados: {df_filtered.shape}")
    
    # Remover linhas com valores faltantes
    df_filtered = df_filtered.dropna()
    
    # Registrar formato ap√≥s remover valores faltantes
    log_step(f"Formato ap√≥s remover valores faltantes: {df_filtered.shape}")
    
    return df_filtered, has_target

def load_best_model():
    """Load the best trained model from the models directory."""
    log_step("Carregando o melhor modelo treinado")
    
    project_root = get_project_root()
    
    # Verificar se temos informa√ß√µes do melhor modelo no arquivo de deployment
    deployment_info_path = os.path.join(project_root, "models", "deployment", "model_info.yaml")
    
    if os.path.exists(deployment_info_path):
        log_step(f"Carregando informa√ß√µes de deployment de: {deployment_info_path}")
        try:
            with open(deployment_info_path, "r") as f:
                model_info = yaml.safe_load(f)
            
            model_name = model_info.get("model_name")
            model_type = model_info.get("model_type")
            
            log_step(f"Informa√ß√µes do modelo encontradas: {model_name} ({model_type})")
            
            if model_type == "Regression":
                model_path = os.path.join(project_root, "models", "regression", f"{model_name}.joblib")
            else:  # Classification
                model_path = os.path.join(project_root, "models", "classification", f"{model_name}.pkl")
                
            if os.path.exists(model_path):
                log_step(f"Carregando modelo de: {model_path}")
                model = joblib.load(model_path)
                return model
        except Exception as e:
            log_step(f"Erro ao carregar modelo a partir das informa√ß√µes de deployment: {str(e)}")
    
    # Se n√£o encontrou o modelo pelo arquivo de deployment, tenta encontrar diretamente
    models_dir = os.path.join(project_root, "models", "classification")
    
    # Procurar pelo melhor modelo salvo
    model_path = os.path.join(models_dir, "logistic_regression.pkl")
    if os.path.exists(model_path):
        log_step(f"Carregando modelo de regress√£o log√≠stica de: {model_path}")
        model = joblib.load(model_path)
    else:
        model_path = os.path.join(models_dir, "decision_tree.pkl")
        if os.path.exists(model_path):
            log_step(f"Carregando modelo de √°rvore de decis√£o de: {model_path}")
            model = joblib.load(model_path)
        else:
            # Tente buscar no registro MLflow
            log_step("Buscando o melhor modelo no registro MLflow")
            try:
                # Buscar √∫ltimo modelo registrado
                client = mlflow.tracking.MlflowClient()
                registered_models = client.list_registered_models()
                
                if registered_models:
                    latest_model_name = registered_models[0].name
                    model_uri = f"models:/{latest_model_name}/latest"
                    model = mlflow.sklearn.load_model(model_uri)
                    log_step(f"Modelo carregado do registro MLflow: {model_uri}")
                else:
                    raise FileNotFoundError("Nenhum modelo registrado encontrado")
            except Exception as e:
                log_step(f"Erro ao buscar modelo do MLflow: {str(e)}")
                raise
    
    return model

def apply_model_to_production_data(model, production_data):
    """Apply the trained model to production data."""
    log_step("Aplicando modelo aos dados de produ√ß√£o")
    
    try:
        # Preparar os dados para predi√ß√£o
        log_step(f"Formato dos dados de entrada: {production_data.shape}")
        
        # Criar uma c√≥pia para n√£o modificar os dados originais
        X = production_data.copy()
        
        # Se a coluna shot_made_flag existir, vamos salv√°-la para uso posterior e remov√™-la dos dados de entrada
        y_true = None
        if 'shot_made_flag' in X.columns:
            log_step("Removendo coluna shot_made_flag dos dados de entrada para predi√ß√£o")
            y_true = X['shot_made_flag'].copy()
            X = X.drop('shot_made_flag', axis=1)
        
        # Problema: O modelo espera features espec√≠ficas em uma ordem espec√≠fica
        # Solu√ß√£o: Verificar as feature names do modelo e reordenar as colunas de X
        expected_feature_names = None
        
        # Tentar obter os nomes das features do modelo
        if hasattr(model, 'feature_names_in_'):
            expected_feature_names = model.feature_names_in_.tolist()
            log_step(f"Feature names do modelo: {expected_feature_names}")
        else:
            # Se o modelo n√£o tiver feature_names_in_, usar uma ordem padr√£o
            expected_feature_names = ['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance']
            log_step(f"Usando ordem padr√£o de features: {expected_feature_names}")
        
        # Verificar se todas as colunas necess√°rias est√£o presentes
        missing_cols = set(expected_feature_names) - set(X.columns)
        if missing_cols:
            log_step(f"AVISO: Colunas ausentes nos dados de entrada: {missing_cols}")
            # Adicionar colunas faltantes com zeros
            for col in missing_cols:
                X[col] = 0
        
        # Verificar se h√° colunas extras nos dados de entrada que n√£o est√£o no modelo
        extra_cols = set(X.columns) - set(expected_feature_names)
        if extra_cols:
            log_step(f"AVISO: Colunas extras nos dados de entrada que ser√£o ignoradas: {extra_cols}")
        
        # Reordenar as colunas para garantir a mesma ordem usada no treinamento
        X = X[expected_feature_names]
        log_step(f"Colunas reordenadas para predi√ß√£o: {X.columns.tolist()}")
        
        # Fazer predi√ß√µes usando sklearn diretamente
        if hasattr(model, 'predict_proba'):
            # Predi√ß√µes de probabilidade
            y_pred_proba = model.predict_proba(X)[:, 1]
            # Predi√ß√µes de classe
            y_pred = model.predict(X)
            
            # Criar dataframe de resultados
            predictions = production_data.copy()
            predictions['prediction_score'] = y_pred_proba
            predictions['prediction_label'] = y_pred
            
            log_step("Predi√ß√µes realizadas com sucesso")
            return predictions
        else:
            raise ValueError("O modelo n√£o possui m√©todo predict_proba")
            
    except Exception as e:
        log_step(f"Erro ao aplicar o modelo: {str(e)}")
        
        # Adicionar mais detalhes para diagn√≥stico
        if "feature names" in str(e).lower():
            if hasattr(model, 'feature_names_in_'):
                log_step(f"Features esperadas pelo modelo: {model.feature_names_in_.tolist()}")
            log_step(f"Features fornecidas: {X.columns.tolist() if 'X' in locals() else 'N/A'}")
        
        raise

def evaluate_predictions(predictions, has_target):
    """Evaluate model predictions if target variable is available."""
    log_step("Avaliando predi√ß√µes do modelo")
    
    if not has_target:
        log_step("Alvo 'shot_made_flag' n√£o dispon√≠vel nos dados de produ√ß√£o. N√£o √© poss√≠vel avaliar m√©tricas.")
        return None
    
    try:
        # Extrair valores reais e preditos
        y_true = predictions['shot_made_flag'].values
        
        # Extrair probabilidades preditas
        if 'prediction_score' in predictions.columns:
            y_prob = predictions['prediction_score'].values
        else:
            # Tentar encontrar coluna de probabilidade
            prob_cols = [col for col in predictions.columns if 'score' in col.lower() or 'prob' in col.lower()]
            if prob_cols:
                y_prob = predictions[prob_cols[0]].values
            else:
                log_step("Coluna com probabilidades n√£o encontrada. N√£o √© poss√≠vel calcular log loss.")
                y_prob = None
        
        # Extrair classes preditas
        if 'prediction_label' in predictions.columns:
            y_pred = predictions['prediction_label'].values
        else:
            # Tentar encontrar coluna de predi√ß√£o
            pred_cols = [col for col in predictions.columns if 'pred' in col.lower() or 'label' in col.lower()]
            if pred_cols:
                y_pred = predictions[pred_cols[0]].values
            else:
                log_step("Coluna com predi√ß√µes n√£o encontrada. N√£o √© poss√≠vel calcular f1-score.")
                y_pred = None
        
        # Calcular m√©tricas
        metrics = {}
        
        if y_prob is not None:
            log_loss_value = log_loss(y_true, y_prob)
            metrics['log_loss'] = log_loss_value
            log_step(f"Log Loss: {log_loss_value:.4f}")
        
        if y_pred is not None:
            f1_score_value = f1_score(y_true, y_pred)
            metrics['f1_score'] = f1_score_value
            log_step(f"F1 Score: {f1_score_value:.4f}")
        
        return metrics
    
    except Exception as e:
        log_step(f"Erro ao calcular m√©tricas: {str(e)}")
        return None

def save_results(predictions, metrics):
    """Save prediction results and log metrics."""
    log_step("Salvando resultados e registrando m√©tricas")
    
    # Criar diret√≥rio para resultados
    project_root = get_project_root()
    results_dir = os.path.join(project_root, "data", "results")
    os.makedirs(results_dir, exist_ok=True)
    
    # Salvar predi√ß√µes como parquet
    results_path = os.path.join(results_dir, f"production_predictions_{datetime.now().strftime('%Y%m%d%H%M%S')}.parquet")
    predictions.to_parquet(results_path)
    log_step(f"Predi√ß√µes salvas em: {results_path}")
    
    # Registrar arquivo como artefato no MLflow
    mlflow.log_artifact(results_path, "prediction_results")
    
    # Registrar m√©tricas no MLflow, se dispon√≠veis
    if metrics:
        for metric_name, metric_value in metrics.items():
            mlflow.log_metric(metric_name, metric_value)
        
        # Salvar m√©tricas tamb√©m como CSV para o dashboard
        metrics_path = os.path.join(results_dir, "metrics.csv")
        metrics_dict = metrics.copy()
        metrics_dict['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Verificar se o arquivo j√° existe
        metrics_df = None
        if os.path.exists(metrics_path):
            try:
                metrics_df = pd.read_csv(metrics_path)
                # Adicionar nova linha
                metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics_dict])])
            except:
                metrics_df = pd.DataFrame([metrics_dict])
        else:
            metrics_df = pd.DataFrame([metrics_dict])
            
        # Salvar CSV atualizado
        metrics_df.to_csv(metrics_path, index=False)
    
    return results_path

def create_monitoring_dashboard(predictions, results_path, metrics):
    """Create a monitoring dashboard using Streamlit."""
    log_step("Criando dashboard de monitoramento")
    
    # Criar diret√≥rio para a aplica√ß√£o Streamlit
    project_root = get_project_root()
    app_dir = os.path.join(project_root, "app")
    os.makedirs(app_dir, exist_ok=True)
    
    # Criar aplica√ß√£o Streamlit
    app_path = os.path.join(app_dir, "monitoring_dashboard.py")
    
    # Lista de fragmentos de c√≥digo para o dashboard
    code_fragments = []
    
    # Importa√ß√µes e configura√ß√µes
    code_fragments.append("""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Dashboard de Monitoramento do Modelo - Kobe Bryant Shot Prediction",
    layout="wide"
)

# Fun√ß√µes auxiliares
def get_project_root():
    current_path = Path(__file__).resolve()
    return current_path.parent.parent

def load_predictions():
    # Encontrar o arquivo de predi√ß√µes mais recente
    project_root = get_project_root()
    results_dir = os.path.join(project_root, "data", "results")
    
    if not os.path.exists(results_dir):
        st.error("Diret√≥rio de resultados n√£o encontrado")
        return None
    
    # Listar arquivos de predi√ß√£o
    prediction_files = [f for f in os.listdir(results_dir) if f.startswith("production_predictions_") and f.endswith(".parquet")]
    
    if not prediction_files:
        st.error("Nenhum arquivo de predi√ß√µes encontrado")
        return None
    
    # Ordenar por data (mais recente primeiro)
    latest_file = sorted(prediction_files, reverse=True)[0]
    file_path = os.path.join(results_dir, latest_file)
    
    # Carregar dados
    try:
        return pd.read_parquet(file_path)
    except Exception as e:
        st.error(f"Erro ao carregar arquivo de predi√ß√µes: {str(e)}")
        return None

# T√≠tulo principal
st.title("Dashboard de Monitoramento - Predi√ß√£o de Arremessos do Kobe Bryant")

# Barra lateral com informa√ß√µes do modelo
st.sidebar.title("Informa√ß√µes do Modelo")

# Carregar m√©tricas do √∫ltimo execu√ß√£o
has_metrics = False
try:
    project_root = get_project_root()
    metrics_file = os.path.join(project_root, "data", "results", "metrics.csv")
    if os.path.exists(metrics_file):
        metrics_df = pd.read_csv(metrics_file)
        latest_metrics = metrics_df.iloc[-1].to_dict()
        has_metrics = True
        
        # Carregar hist√≥rico completo de m√©tricas para gr√°ficos de tend√™ncia
        metrics_history = metrics_df.copy()
        metrics_history['timestamp'] = pd.to_datetime(metrics_history['timestamp'])
    else:
        # M√©tricas de exemplo caso o arquivo n√£o exista
        latest_metrics = {
            'log_loss': 0.5423,
            'f1_score': 0.6812,
            'timestamp': '2025-04-12 15:30:00'
        }
except Exception as e:
    st.sidebar.error(f"Erro ao carregar m√©tricas: {str(e)}")
    # M√©tricas de exemplo em caso de erro
    latest_metrics = {
        'log_loss': 0.5423,
        'f1_score': 0.6812,
        'timestamp': '2025-04-12 15:30:00'
    }

# Exibir m√©tricas do modelo
st.sidebar.header("M√©tricas do Modelo")
st.sidebar.metric("Log Loss", f"{latest_metrics.get('log_loss', 'N/A'):.4f}")
st.sidebar.metric("F1 Score", f"{latest_metrics.get('f1_score', 'N/A'):.4f}")
st.sidebar.text(f"√öltima atualiza√ß√£o: {latest_metrics.get('timestamp', 'Desconhecido')}")

# Exibir informa√ß√µes do modelo
st.sidebar.header("Detalhes do Modelo")
st.sidebar.write("**Tipo:** Classifica√ß√£o Bin√°ria")
st.sidebar.write("**Objetivo:** Prever se o arremesso do Kobe Bryant ser√° convertido (1) ou n√£o (0)")
st.sidebar.write("**Features utilizadas:**")
st.sidebar.write("- Localiza√ß√£o (lat, lon)")
st.sidebar.write("- Minutos restantes")
st.sidebar.write("- Per√≠odo (quarter)")
st.sidebar.write("- Playoffs (sim/n√£o)")
st.sidebar.write("- Dist√¢ncia do arremesso")
""")

    # Tabs e conte√∫do principal
    code_fragments.append("""
# Tabs para organizar o dashboard
tab1, tab2, tab3 = st.tabs(["Vis√£o Geral", "An√°lise de Predi√ß√µes", "Sa√∫de do Modelo"])

# Tab 1: Vis√£o Geral
with tab1:
    st.header("Vis√£o Geral das Predi√ß√µes")
    
    # Carregar dados de predi√ß√µes
    predictions = load_predictions()
    
    if predictions is not None:
        # Resumo das predi√ß√µes
        st.write(f"Total de arremessos analisados: {len(predictions)}")
        
        # Layout de duas colunas
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o de predi√ß√µes
            st.subheader("Distribui√ß√£o das Predi√ß√µes")
            if 'prediction_label' in predictions.columns:
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.countplot(x='prediction_label', data=predictions, ax=ax)
                ax.set_xlabel("Arremesso Convertido (1) vs Errado (0)")
                ax.set_ylabel("Contagem")
                ax.set_title("Distribui√ß√£o das Predi√ß√µes")
                st.pyplot(fig)
            else:
                st.info("Coluna de predi√ß√£o n√£o encontrada nos dados")
        
        with col2:
            # Distribui√ß√£o da confian√ßa nas predi√ß√µes
            st.subheader("Distribui√ß√£o da Confian√ßa")
            if 'prediction_score' in predictions.columns:
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.histplot(predictions['prediction_score'], bins=20, ax=ax)
                ax.set_xlabel("Score de Probabilidade")
                ax.set_ylabel("Frequ√™ncia")
                ax.set_title("Distribui√ß√£o das Probabilidades Preditas")
                st.pyplot(fig)
            else:
                st.info("Coluna de score n√£o encontrada nos dados")
        
        # Mostrar dados brutos
        with st.expander("Ver Dados Brutos"):
            st.dataframe(predictions)
""")

    # Tab 2 - An√°lise de Predi√ß√µes
    code_fragments.append("""
# Tab 2: An√°lise de Predi√ß√µes
with tab2:
    st.header("An√°lise Detalhada das Predi√ß√µes")
    
    if predictions is not None:
        # Layout de duas colunas
        col1, col2 = st.columns(2)
        
        with col1:
            # An√°lise por dist√¢ncia de arremesso
            st.subheader("Predi√ß√µes por Dist√¢ncia de Arremesso")
            
            if 'shot_distance' in predictions.columns and 'prediction_label' in predictions.columns:
                # Criar bins para dist√¢ncias
                predictions['distance_bin'] = pd.cut(
                    predictions['shot_distance'],
                    bins=[0, 5, 10, 15, 20, 25, 30, 100],
                    labels=['0-5', '5-10', '10-15', '15-20', '20-25', '25-30', '30+']
                )
                
                # Calcular taxa de convers√£o por bin de dist√¢ncia
                dist_conversion = predictions.groupby('distance_bin')['prediction_label'].mean().reset_index()
                
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.barplot(x='distance_bin', y='prediction_label', data=dist_conversion, ax=ax)
                ax.set_xlabel("Dist√¢ncia (p√©s)")
                ax.set_ylabel("Taxa de Convers√£o Predita")
                ax.set_title("Taxa de Convers√£o por Dist√¢ncia")
                plt.xticks(rotation=45)
                st.pyplot(fig)
            else:
                st.info("Colunas necess√°rias n√£o encontradas nos dados")
        
        with col2:
            # An√°lise por per√≠odo
            st.subheader("Predi√ß√µes por Per√≠odo (Quarter)")
            
            if 'period' in predictions.columns and 'prediction_label' in predictions.columns:
                period_conversion = predictions.groupby('period')['prediction_label'].mean().reset_index()
                
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.barplot(x='period', y='prediction_label', data=period_conversion, ax=ax)
                ax.set_xlabel("Per√≠odo")
                ax.set_ylabel("Taxa de Convers√£o Predita")
                ax.set_title("Taxa de Convers√£o por Per√≠odo")
                st.pyplot(fig)
            else:
                st.info("Colunas necess√°rias n√£o encontradas nos dados")
        
        # Mapa de calor das localiza√ß√µes (se dispon√≠vel)
        if 'lat' in predictions.columns and 'lon' in predictions.columns:
            st.subheader("Mapa de Calor das Localiza√ß√µes")
            
            fig, ax = plt.subplots(figsize=(10, 9))
            ax.set_xlim(-250, 250)
            ax.set_ylim(-50, 450)
            
            # Desenhar quadra de basquete (simplificada)
            # C√≠rculo central
            circle = plt.Circle((0, 140), 60, fill=False, color='black')
            ax.add_artist(circle)
            
            # Linha de 3 pontos
            three_point_line_y = 0.0
            three_point_radius = 237.5
            three_point_line = plt.Circle((0, three_point_line_y), three_point_radius, fill=False, linestyle='--', color='black')
            ax.add_artist(three_point_line)
            
            # Cesta
            basket = plt.Circle((0, 0), 7.5, fill=False, color='red')
            ax.add_artist(basket)
            
            # √Årea restrita
            restricted_area = plt.Circle((0, 0), 40, fill=False, color='black')
            ax.add_artist(restricted_area)
            
            # Linha de lance livre
            ax.plot([-80, 80], [140, 140], color='black')
            
            # Distribui√ß√£o de pontos coloridos por predi√ß√£o
            scatter = ax.scatter(
                predictions['lon'], 
                predictions['lat'],
                c=predictions['prediction_score'] if 'prediction_score' in predictions.columns else predictions['prediction_label'],
                cmap='coolwarm', 
                alpha=0.7, 
                s=20
            )
            plt.colorbar(scatter, label='Probabilidade de Convers√£o' if 'prediction_score' in predictions.columns else 'Predi√ß√£o')
            
            ax.set_title('Mapa de Calor das Predi√ß√µes na Quadra')
            ax.set_xlabel('Coordenada X')
            ax.set_ylabel('Coordenada Y')
            ax.set_aspect('equal')
            st.pyplot(fig)
        else:
            st.info("Coordenadas de localiza√ß√£o n√£o encontradas nos dados")
""")

    # Tab 3 - Sa√∫de do Modelo (parte 1)
    code_fragments.append("""
# Tab 3: Sa√∫de do Modelo
with tab3:
    st.header("Monitoramento da Sa√∫de do Modelo")
    
    # Tend√™ncias de m√©tricas ao longo do tempo
    st.subheader("Tend√™ncias de M√©tricas ao Longo do Tempo")
    
    # Usar dados reais se dispon√≠veis, caso contr√°rio dados simulados
    if 'metrics_history' in locals() and len(metrics_history) > 1:
        col1, col2 = st.columns(2)
        
        with col1:
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(metrics_history['timestamp'], metrics_history['log_loss'], marker='o')
            ax.set_title('Tend√™ncia de Log Loss')
            ax.set_xlabel('Data')
            ax.set_ylabel('Log Loss (menor √© melhor)')
            plt.xticks(rotation=45)
            ax.grid(True)
            st.pyplot(fig)
        
        with col2:
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(metrics_history['timestamp'], metrics_history['f1_score'], marker='o', color='green')
            ax.set_title('Tend√™ncia de F1-Score')
            ax.set_xlabel('Data')
            ax.set_ylabel('F1-Score (maior √© melhor)')
            plt.xticks(rotation=45)
            ax.grid(True)
            st.pyplot(fig)
    else:
        # Dados simulados para m√©tricas hist√≥ricas
        dates = pd.date_range(end=pd.Timestamp.now(), periods=10).to_pydatetime()
        metrics_history_sim = pd.DataFrame({
            'timestamp': dates,
            'log_loss': np.random.normal(0.58, 0.03, 10),
            'f1_score': np.random.normal(0.65, 0.02, 10)
        })
        
        # Exibir gr√°ficos de tend√™ncia simulados
        col1, col2 = st.columns(2)
        
        with col1:
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(metrics_history_sim['timestamp'], metrics_history_sim['log_loss'], marker='o')
            ax.set_title('Tend√™ncia de Log Loss (Simulado)')
            ax.set_xlabel('Data')
            ax.set_ylabel('Log Loss (menor √© melhor)')
            plt.xticks(rotation=45)
            ax.grid(True)
            st.pyplot(fig)
        
        with col2:
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(metrics_history_sim['timestamp'], metrics_history_sim['f1_score'], marker='o', color='green')
            ax.set_title('Tend√™ncia de F1-Score (Simulado)')
            ax.set_xlabel('Data')
            ax.set_ylabel('F1-Score (maior √© melhor)')
            plt.xticks(rotation=45)
            ax.grid(True)
            st.pyplot(fig)
""")

    # Tab 3 - Sa√∫de do Modelo (parte 2) - Parte problem√°tica com corre√ß√£o
    code_fragments.append('''
    # Detec√ß√£o de desvio de dados (data drift)
    st.subheader("Detec√ß√£o de Desvio de Dados (Data Drift)")
    
    st.write(
        "Para detectar desvio nos dados (data drift) ao longo do tempo, monitoramos a distribui√ß√£o "
        "das principais vari√°veis em compara√ß√£o com o conjunto de dados de treinamento."
    )
    
    # Simula√ß√£o de desvio em uma das vari√°veis
    if predictions is not None and 'shot_distance' in predictions.columns:
        # Dados simulados para compara√ß√£o com treinamento
        train_distances = np.random.normal(15, 5, 1000)  # Simula√ß√£o de distribui√ß√£o no treino
        
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.kdeplot(train_distances, label='Distribui√ß√£o no Treino', color='blue', ax=ax)
        sns.kdeplot(predictions['shot_distance'], label='Distribui√ß√£o Atual', color='red', ax=ax)
        ax.set_title('Compara√ß√£o da Distribui√ß√£o de Dist√¢ncia de Arremesso')
        ax.set_xlabel('Dist√¢ncia (p√©s)')
        ax.legend()
        plt.grid(True)
        st.pyplot(fig)
        
        # Alerta simulado de desvio
        drift_detected = np.random.choice([True, False], p=[0.3, 0.7])  # Simula√ß√£o de detec√ß√£o
        if drift_detected:
            st.warning("‚ö†Ô∏è **Alerta de Desvio Detectado!**\\n\\nA distribui√ß√£o atual da dist√¢ncia de arremesso est√° significativamente diferente da distribui√ß√£o usada no treinamento. Considere reavaliar o modelo.")
        else:
            st.success("‚úÖ Nenhum desvio significativo detectado nas vari√°veis de entrada.")
    
    # A√ß√£o recomendada
    st.subheader("Recomenda√ß√µes de A√ß√£o")
    
    if has_metrics and latest_metrics.get('log_loss', 0) > 0.6:
        st.error("üî¥ **A√ß√£o recomendada**: Retreinamento do modelo\\n\\nO Log Loss atual est√° acima do limite aceit√°vel (0.6), indicando degrada√ß√£o no desempenho do modelo. Recomendamos retreinar o modelo com dados mais recentes.")
    else:
        st.success("üü¢ **Status atual**: Saud√°vel\\n\\nO modelo est√° operando dentro dos par√¢metros esperados. Continue monitorando regularmente para detectar mudan√ßas no desempenho.")
''')

    # Rodap√©
    code_fragments.append("""
# Rodap√©
st.markdown("---")
st.caption("Dashboard de Monitoramento do Modelo - Kobe Bryant Shot Prediction - Powered by Streamlit")
""")
    
    # Unir todos os fragmentos de c√≥digo em um √∫nico arquivo
    with open(app_path, "w", encoding='utf-8') as f:
        dashboard_code = "".join(code_fragments)
        f.write(dashboard_code)

    log_step(f"Dashboard de monitoramento criado em: {app_path}")
    return app_path

def retrain_model_with_new_data(predictions, has_target):
    """Retreina o modelo com os novos dados de produ√ß√£o."""
    if not has_target:
        log_step("N√£o √© poss√≠vel retreinar o modelo: dados de produ√ß√£o n√£o cont√™m a coluna target 'shot_made_flag'")
        return None
    
    log_step("Iniciando processo de retreinamento com novos dados de produ√ß√£o")
    
    try:
        # Importar fun√ß√£o de retreinamento
        from retraining_pipeline import retrain_model
        
        # Chamar fun√ß√£o de retreinamento passando os dados de produ√ß√£o
        new_model = retrain_model(predictions)
        
        log_step("Modelo retreinado com sucesso!")
        return new_model
    except ImportError:
        log_step("M√≥dulo de retreinamento n√£o encontrado. Skipping.")
        return None
    except Exception as e:
        log_step(f"Erro durante o retreinamento: {str(e)}")
        return None

def main():
    """Main function to run the application pipeline."""
    log_step("Iniciando pipeline de aplica√ß√£o")

    try:
        # Etapa 1: Carregar dados de produ√ß√£o
        production_data = load_production_data()
        log_step(f"Dados de produ√ß√£o carregados. Formato: {production_data.shape}")

        # Etapa 2: Filtrar dados
        filtered_data, has_target = filter_production_data(production_data)
        log_step(f"Dados filtrados. Formato final: {filtered_data.shape}")

        # Etapa 3: Carregar o melhor modelo
        best_model = load_best_model()

        # Etapa 4: Aplicar modelo aos dados de produ√ß√£o
        predictions = apply_model_to_production_data(best_model, filtered_data)

        # Etapa 5: Avaliar predi√ß√µes (se target estiver dispon√≠vel)
        metrics = evaluate_predictions(predictions, has_target)

        # Etapa 6: Salvar resultados e registrar m√©tricas
        results_path = save_results(predictions, metrics)

        # Etapa 7: Criar dashboard de monitoramento
        app_path = create_monitoring_dashboard(predictions, results_path, metrics)
        
        # Etapa 8: Retreinar o modelo com novos dados (NOVA FUNCIONALIDADE)
        should_retrain = True  # Definir como par√¢metro ou configura√ß√£o
        if should_retrain and has_target:
            log_step("Iniciando retreinamento do modelo com novos dados")
            new_model = retrain_model_with_new_data(predictions, has_target)
            if new_model:
                log_step("Modelo retreinado e atualizado com sucesso!")
            else:
                log_step("Retreinamento n√£o foi bem sucedido, mantendo modelo atual")

        log_step("Pipeline de aplica√ß√£o conclu√≠do com sucesso")
        log_step(f"Para visualizar o dashboard, execute: streamlit run {app_path}")

        return True

    except Exception as e:
        log_step(f"Erro no pipeline de aplica√ß√£o: {str(e)}")
        raise

if __name__ == "__main__":
    # Iniciar run do MLflow para rastreamento com o nome especificado
    with mlflow.start_run(run_name="PipelineAplicacao"):
        main()